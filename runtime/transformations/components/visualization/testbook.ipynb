{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import logging\n",
    "import math\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from pydantic import BaseModel, ValidationError, root_validator, validator\n",
    "\n",
    "#rom hetdesrun.utils import plotly_fig_to_json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComponentInputValidationException(Exception):\n",
    "    \"\"\"In code input validation failures\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        invalid_component_inputs: list[str],\n",
    "        error_code: int | str = \"\",\n",
    "        **kwargs: Any\n",
    "    ):\n",
    "        raise ValueError(\"Hier könnte ihr Error stehen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapDetectionParameters(BaseModel):\n",
    "    start_date: str  # pydantic kann auch direkt datetime, muss aber getestet werden\n",
    "    end_date: str\n",
    "    auto_stepsize: bool = True\n",
    "    history_end_date: str = None\n",
    "    step_size_str: str = None\n",
    "    percentil: float\n",
    "    min_amount_datapoints: int\n",
    "    add_gapsize_column: bool = True\n",
    "\n",
    "    @validator(\n",
    "        \"start_date\", \"end_date\"\n",
    "    )  # TODO was ist mit dem Fall Attribut der Zeitreihe?\n",
    "    def verify_date_strings(cls, date) -> datetime:\n",
    "        date = datetime.fromisoformat(date).replace(tzinfo=timezone.utc)\n",
    "        return date\n",
    "\n",
    "    @validator(\"end_date\")\n",
    "    def verify_dates(cls, end_date, values: dict):\n",
    "        start_date = values[\"start_date\"]\n",
    "        if start_date > end_date:\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The value start_date must not be later than the end_date, while it is \"\n",
    "                f\"{start_date} > {end_date}.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"end_date_str\", \"start_date_str\"],\n",
    "            )\n",
    "        return values\n",
    "\n",
    "    @validator(\"history_end_date\")\n",
    "    def verify_history_end_date(cls, history_end_date, values: dict) -> datetime | None:\n",
    "        start_date = values[\"start_date\"]\n",
    "        end_date = values[\"end_date\"]\n",
    "        if history_end_date is not None:\n",
    "            try:\n",
    "                history_end_date = datetime.fromisoformat(history_end_date).replace(\n",
    "                    tzinfo=timezone.utc\n",
    "                )\n",
    "            except ValueError as err:\n",
    "                raise ComponentInputValidationException(\n",
    "                    \"The date in history_end_date has to be formatted in iso format to allow \"\n",
    "                    \"conversion to datetime type for gap detection.\",\n",
    "                    error_code=422,\n",
    "                    invalid_component_inputs=[\"history_end_date_str\"],\n",
    "                ) from err\n",
    "\n",
    "            if start_date > history_end_date:\n",
    "                raise ComponentInputValidationException(\n",
    "                    \"The value history_end_date has to be inbetween start_date and end_date, while \"\n",
    "                    f\"it is {history_end_date} < {start_date}.\",\n",
    "                    error_code=422,\n",
    "                    invalid_component_inputs=[\"history_end_date_str\"],\n",
    "                )\n",
    "            if end_date < history_end_date:\n",
    "                raise ComponentInputValidationException(\n",
    "                    \"The value history_end_date has to be inbetween start_date and end_date, while \"\n",
    "                    f\"it is {history_end_date} > {end_date}.\",\n",
    "                    error_code=422,\n",
    "                    invalid_component_inputs=[\"history_end_date_str\"],\n",
    "                )\n",
    "        else:\n",
    "            history_end_date = None\n",
    "        return history_end_date\n",
    "\n",
    "    @validator(\"step_size_str\")  # TODO auf freq string überprüfen\n",
    "    def verify_step_size(cls, step_size, values: dict) -> str:\n",
    "        auto_stepsize = values[\"auto_stepsize\"]\n",
    "        if (auto_stepsize is False) and (step_size is None):\n",
    "            raise ComponentInputValidationException(\n",
    "                \"A step_size is required for gap detection, if it is not automatically determined.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"step_size_str\"],\n",
    "            )\n",
    "        return step_size\n",
    "\n",
    "    @validator(\"percentil\")\n",
    "    def verify_percentile(cls, percentil) -> int:\n",
    "        if (percentil < 0) or (percentil > 100):\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The percentil value has to be a non-negative integer less or equal to 100.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"percentil\"],\n",
    "            )\n",
    "        return percentil\n",
    "\n",
    "    @validator(\"min_amount_datapoints\")\n",
    "    def verify__min_amount_datapoints(cls, min_amount) -> int:\n",
    "        if min_amount < 0:\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The minimum amount of datapoints has to be a non-negative integer.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"min_amount_datapoints\"],\n",
    "            )\n",
    "        return min_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrict_series_to_dates(\n",
    "    timeseries_data: pd.Series | pd.DataFrame, start_date: datetime, end_date: datetime\n",
    ") -> pd.Series | pd.DataFrame:\n",
    "    return timeseries_data[\n",
    "        (timeseries_data.index >= start_date) & (timeseries_data.index <= end_date)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_amount_datapoints(series:pd.Series, min_amount_datapoints:int):\n",
    "    if len(series) < min_amount_datapoints:\n",
    "            raise ComponentInputValidationException(\n",
    "                f\"The timeseries must contain at least {min_amount_datapoints} datapoints.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"timeseries\"],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_timestep_gapsize_percentile(\n",
    "    timeseries_data: pd.Series | pd.DataFrame, percentil=95\n",
    ") -> pd.Timedelta:\n",
    "    gaps = timeseries_data.index.to_series().diff().dropna()\n",
    "\n",
    "    percentile_gapsize = gaps.quantile(\n",
    "        percentil / 100, interpolation=\"nearest\"\n",
    "    )  #  TODO nachfragen wegen Interpol\n",
    "\n",
    "    return percentile_gapsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqstr2dateoffset(freqstr: str) -> pd.DateOffset:\n",
    "    \"\"\"Transform frequency string to Pandas DateOffset.\"\"\"\n",
    "    return pd.tseries.frequencies.to_offset(freqstr)\n",
    "\n",
    "def freqstr2timedelta(freqstr: str) -> pd.Timedelta:\n",
    "    \"\"\"Transform frequency string to Pandas Timedelta.\"\"\"\n",
    "    try:\n",
    "        return pd.to_timedelta(freqstr)\n",
    "    except ValueError:\n",
    "        return pd.to_timedelta(freqstr2dateoffset(freqstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_gap_length(\n",
    "    timeseries: pd.Series, stepsize=timedelta(minutes=1)\n",
    ") -> pd.DataFrame:\n",
    "    gaps = timeseries.index.to_series().diff().to_numpy()\n",
    "\n",
    "    stepsize_seconds = stepsize.total_seconds()\n",
    "\n",
    "    normalized_gaps = [\n",
    "        pd.Timedelta(gap).total_seconds() / stepsize_seconds if pd.notnna(gap) else None\n",
    "        for gap in gaps\n",
    "    ]\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        {\"value\": timeseries.to_numpy(), \"gap\": normalized_gaps}, index=timeseries.index\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_add_boundary_dates(\n",
    "    timeseries: pd.Series, start_date: datetime, end_date: datetime, dummy_value=math.pi\n",
    ") -> pd.Series:\n",
    "    if start_date not in timeseries.index:\n",
    "        timeseries[start_date] = dummy_value\n",
    "\n",
    "    if end_date not in timeseries.index:\n",
    "        timeseries[end_date] = dummy_value\n",
    "\n",
    "    timeseries = timeseries.sort_index()\n",
    "\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_ts=366\n",
    "timeseries = pd.Series(data=range(length_ts),index=pd.to_datetime(range(length_ts),utc=True,unit=\"D\",origin=\"2020-01-01T01:15:27.000\"))\n",
    "start_date = \"2020-01-01T01:15:27.000Z\"\n",
    "end_date= \"2020-12-31T01:15:27.000Z\"\n",
    "auto_stepsize = True\n",
    "history_end_date= \"2020-01-01T01:15:27.000Z\"\n",
    "step_size_str= \"\"\n",
    "percentil = 95\n",
    "min_amount_datapoints = 21\n",
    "add_gapsize_column = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(timeseries=timeseries,start_date_str=start_date,end_date_str=end_date,\n",
    "                       auto_stepsize=auto_stepsize,history_end_date_str=history_end_date,step_size_str=step_size_str,percentil=percentil,\n",
    "                       min_amount_datapoints=min_amount_datapoints,add_gapsize_column=add_gapsize_column):\n",
    "    timeseries = timeseries.dropna()\n",
    "\n",
    "    input_params = GapDetectionParameters(\n",
    "        start_date=start_date_str,\n",
    "        end_date=end_date_str,\n",
    "        auto_stepsize=auto_stepsize,\n",
    "        history_end_date_str=history_end_date_str,\n",
    "        step_size=step_size_str,\n",
    "        percentil=percentil,\n",
    "        min_amount_datapoints=min_amount_datapoints,\n",
    "        add_gapsize_column=add_gapsize_column,\n",
    "    )\n",
    "    constricted_series = constrict_series_to_dates(\n",
    "        timeseries, start_date_str, end_date_str\n",
    "    )\n",
    "    check_amount_datapoints(series=constricted_series,min_amount_datapoints=input_params.min_amount_datapoints)\n",
    "    if auto_stepsize:\n",
    "        if input_params.history_end_date is not None:\n",
    "            training_series = constrict_series_to_dates(\n",
    "                timeseries, input_params.start_date, input_params.history_end_date\n",
    "            )\n",
    "        else:\n",
    "            training_series = constricted_series\n",
    "        step_size = determine_timestep_gapsize_percentile(training_series, percentil)\n",
    "    else:\n",
    "        step_size = freqstr2timedelta(step_size_str)\n",
    "    series_with_bounds = check_add_boundary_dates(\n",
    "        constricted_series, start_date_str, end_date_str\n",
    "    )\n",
    "\n",
    "    df_with_gaps = determine_gap_length(series_with_bounds, step_size)\n",
    "    gap_boundaries = return_gap_boundary_timestamps(df_with_gaps)\n",
    "\n",
    "    return gap_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GapDetectionParameters(start_date=datetime.datetime(2020, 1, 1, 1, 15, 27, tzinfo=datetime.timezone.utc), end_date={'start_date': datetime.datetime(2020, 1, 1, 1, 15, 27, tzinfo=datetime.timezone.utc), 'end_date': {...}, 'auto_stepsize': True, 'history_end_date': None, 'step_size_str': '', 'percentil': 95.0, 'min_amount_datapoints': 21, 'add_gapsize_column': True}, auto_stepsize=True, history_end_date=None, step_size_str='', percentil=95.0, min_amount_datapoints=21, add_gapsize_column=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GapDetectionParameters(start_date=start_date,end_date=end_date,\n",
    "                       auto_stepsize=auto_stepsize,step_size_str=step_size_str,percentil=percentil,\n",
    "                       min_amount_datapoints=min_amount_datapoints,add_gapsize_column=add_gapsize_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hd-runtime-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
