{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import logging\n",
    "import math\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from pydantic import BaseModel, ValidationError, root_validator, validator\n",
    "\n",
    "#rom hetdesrun.utils import plotly_fig_to_json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComponentInputValidationException(Exception):\n",
    "    \"\"\"In code input validation failures\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        invalid_component_inputs: list[str],\n",
    "        error_code: int | str = \"\",\n",
    "        **kwargs: Any\n",
    "    ):\n",
    "        raise ValueError(\"Hier könnte ihr Error stehen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapDetectionParameters(BaseModel):\n",
    "    start_date: pd.Timestamp | None  # pydantic kann auch direkt datetime, muss aber getestet werden\n",
    "    end_date: pd.Timestamp  | None\n",
    "    auto_stepsize: bool = True\n",
    "    history_end_date: pd.Timestamp = None\n",
    "    step_size_str: str\n",
    "    percentil: float = 0.5\n",
    "    step_size_factor: float = 1.0\n",
    "    min_amount_datapoints: int\n",
    "    interpolation_method: str = \"nearest\"\n",
    "    fill_value: Any = None\n",
    "\n",
    "    # @validator(\n",
    "    #     \"start_date\", \"end_date\"\n",
    "    # )  # TODO was ist mit dem Fall Attribut der Zeitreihe?\n",
    "    # def verify_date_strings(cls, date) -> datetime:\n",
    "    #     date = datetime.fromisoformat(date).replace(tzinfo=timezone.utc)\n",
    "    #     return date\n",
    "\n",
    "    @validator(\"end_date\")\n",
    "    def verify_dates(cls, end_date, values: dict):\n",
    "        start_date = values[\"start_date\"]\n",
    "        if None not in (start_date,end_date) and start_date > end_date:\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The value start_date must not be later than the end_date, while it is \"\n",
    "                f\"{start_date} > {end_date}.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"end_date_str\", \"start_date_str\"],\n",
    "            )\n",
    "        return end_date\n",
    "\n",
    "    @validator(\"history_end_date\")\n",
    "    def verify_history_end_date(cls, history_end_date, values: dict) -> datetime | None:\n",
    "        start_date = values[\"start_date\"]\n",
    "        end_date = values[\"end_date\"]\n",
    "        if history_end_date is not None:\n",
    "            # try:\n",
    "            #     history_end_date = datetime.fromisoformat(history_end_date).replace(\n",
    "            #         tzinfo=timezone.utc\n",
    "            #     )\n",
    "            # except ValueError as err:\n",
    "            #     raise ComponentInputValidationException(\n",
    "            #         \"The date in history_end_date has to be formatted in iso format to allow \"\n",
    "            #         \"conversion to datetime type for gap detection.\",\n",
    "            #         error_code=422,\n",
    "            #         invalid_component_inputs=[\"history_end_date_str\"],\n",
    "            #     ) from err\n",
    "\n",
    "            if start_date > history_end_date:\n",
    "                raise ComponentInputValidationException(\n",
    "                    \"The value history_end_date has to be inbetween start_date and end_date, while \"\n",
    "                    f\"it is {history_end_date} < {start_date}.\",\n",
    "                    error_code=422,\n",
    "                    invalid_component_inputs=[\"history_end_date_str\"],\n",
    "                )\n",
    "            if end_date < history_end_date:\n",
    "                raise ComponentInputValidationException(\n",
    "                    \"The value history_end_date has to be inbetween start_date and end_date, while \"\n",
    "                    f\"it is {history_end_date} > {end_date}.\",\n",
    "                    error_code=422,\n",
    "                    invalid_component_inputs=[\"history_end_date_str\"],\n",
    "                )\n",
    "        else:\n",
    "            history_end_date = None\n",
    "        return history_end_date\n",
    "\n",
    "    @validator(\"step_size_str\") \n",
    "    def verify_step_size(cls, step_size, values: dict) -> str:\n",
    "        auto_stepsize = values[\"auto_stepsize\"]\n",
    "        if (auto_stepsize is False) and (step_size is None):\n",
    "            raise ComponentInputValidationException(\n",
    "                \"A step_size is required for gap detection, if it is not automatically determined.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"step_size_str\"],\n",
    "            )\n",
    "        return step_size\n",
    "\n",
    "    @validator(\"percentil\")\n",
    "    def verify_percentile(cls, percentil) -> float:\n",
    "        if (percentil < 0) or (percentil > 1):\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The percentil value has to be a non-negative float less or equal to 1.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"percentil\"],\n",
    "            )\n",
    "        return percentil\n",
    "\n",
    "    @validator(\"step_size_factor\")\n",
    "    def verify_step_size_factor(cls, factor) -> float:\n",
    "        if factor < 0:\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The gap size factor has to be a non-negative float.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"step_size_factor\"],\n",
    "            )\n",
    "        return factor\n",
    "\n",
    "    @validator(\"min_amount_datapoints\")\n",
    "    def verify_min_amount_datapoints(cls, min_amount) -> int:\n",
    "        if min_amount < 0:\n",
    "            raise ComponentInputValidationException(\n",
    "                \"The minimum amount of datapoints has to be a non-negative integer.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"min_amount_datapoints\"],\n",
    "            )\n",
    "        return min_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_str_to_pd_timestamp(timestamp: str) -> datetime:\n",
    "    try:\n",
    "        date = pd.to_datetime(timestamp, utc=True)\n",
    "    except ValueError as error:\n",
    "        raise ComponentInputValidationException(\n",
    "            str(error), error_code=422, invalid_component_inputs=[\"...\"]\n",
    "        ) from error\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrict_series_to_dates(\n",
    "    timeseries_data: pd.Series | pd.DataFrame,\n",
    "    start_date: pd.Timestamp | None,\n",
    "    end_date: pd.Timestamp | None,\n",
    ") -> pd.Series | pd.DataFrame:\n",
    "    true_array = np.ones(shape=len(timeseries_data), dtype=bool)\n",
    "    series_after_start = (\n",
    "        timeseries_data.index >= start_date\n",
    "        if start_date is not None\n",
    "        else true_array\n",
    "    )\n",
    "    series_before_end = (\n",
    "        timeseries_data.index <= end_date\n",
    "        if start_date is not None\n",
    "        else true_array\n",
    "    )\n",
    "    return timeseries_data[\n",
    "        series_after_start & series_before_end\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_amount_datapoints(series:pd.Series, min_amount_datapoints:int):\n",
    "    if len(series) < min_amount_datapoints:\n",
    "            raise ComponentInputValidationException(\n",
    "                f\"The timeseries must contain at least {min_amount_datapoints} datapoints.\",\n",
    "                error_code=422,\n",
    "                invalid_component_inputs=[\"timeseries\"],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_timestep_gapsize_percentile(\n",
    "    timeseries_data: pd.Series | pd.DataFrame, percentil:float,interpolation_method:str\n",
    ") -> pd.Timedelta:\n",
    "    gaps = timeseries_data.index.to_series().diff().dropna()\n",
    "\n",
    "    percentile_gapsize = gaps.quantile(\n",
    "        percentil, interpolation= interpolation_method\n",
    "    )\n",
    "\n",
    "    return percentile_gapsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqstr2dateoffset(freqstr: str) -> pd.DateOffset:\n",
    "    \"\"\"Transform frequency string to Pandas DateOffset.\"\"\"\n",
    "    return pd.tseries.frequencies.to_offset(freqstr)\n",
    "\n",
    "def freqstr2timedelta(freqstr: str) -> pd.Timedelta:\n",
    "    \"\"\"Transform frequency string to Pandas Timedelta.\"\"\"\n",
    "    try:\n",
    "        return pd.to_timedelta(freqstr)\n",
    "    except ValueError:\n",
    "        return pd.to_timedelta(freqstr2dateoffset(freqstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_gap_length(\n",
    "    timeseries: pd.Series, stepsize=timedelta(minutes=1)\n",
    ") -> pd.DataFrame:\n",
    "    gaps = timeseries.index.to_series().diff().to_numpy()\n",
    "\n",
    "    stepsize_seconds = stepsize.total_seconds()\n",
    "\n",
    "    normalized_gaps = [\n",
    "        pd.Timedelta(gap).total_seconds() / stepsize_seconds if pd.notna(gap) else None\n",
    "        for gap in gaps\n",
    "    ] #TODO in Doku erklären was eine Gap sein soll\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        {\"value\": timeseries.to_numpy(), \"gap\": normalized_gaps}, index=timeseries.index\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_add_boundary_dates(\n",
    "    timeseries: pd.Series, start_date: datetime, end_date: datetime, fill_value=None\n",
    ") -> pd.Series:\n",
    "    if start_date not in timeseries.index:\n",
    "        timeseries[start_date] = fill_value\n",
    "\n",
    "    if end_date not in timeseries.index:\n",
    "        timeseries[end_date] = fill_value\n",
    "\n",
    "    timeseries = timeseries.sort_index()\n",
    "\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_gap_boundary_timestamps(\n",
    "    frame_with_gapsizes: pd.DataFrame, series: pd.Series, step_size_factor=1.0\n",
    ") -> pd.DataFrame:\n",
    "    # Identify rows where gap is greater than 1\n",
    "    large_gap_indices = frame_with_gapsizes[\n",
    "        frame_with_gapsizes[\"gap\"] > step_size_factor\n",
    "    ].index.to_numpy()\n",
    "    # Extract the start and end timestamps of the gaps\n",
    "    gap_starts = [\n",
    "        frame_with_gapsizes.index[index - 1]\n",
    "        for index, large_gap_index in enumerate(frame_with_gapsizes.index)\n",
    "        if large_gap_index in large_gap_indices\n",
    "    ]\n",
    "\n",
    "    left_values = series[gap_starts].to_numpy()\n",
    "    right_values = series[large_gap_indices].to_numpy()\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    result_df = pd.DataFrame(\n",
    "        {\n",
    "            \"start\": gap_starts,\n",
    "            \"end\": large_gap_indices,\n",
    "            \"start_inclusive\": False,\n",
    "            \"end_inclusive\": False,\n",
    "            \"gap_size\": large_gap_indices - gap_starts,\n",
    "            \"value_to_left\": left_values,\n",
    "            \"value_to_right\": right_values,\n",
    "            \"mean_left_right\": (left_values + right_values) / 2\n",
    "            if None not in (left_values, right_values)\n",
    "            else None,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_ts = 366\n",
    "timeseries = pd.Series(\n",
    "    data=range(length_ts),\n",
    "    index=pd.to_datetime(\n",
    "        range(length_ts), utc=True, unit=\"D\", origin=\"2020-01-01T01:15:27.000\"\n",
    "    ),\n",
    ")\n",
    "start_date = \"2019-01-01T01:15:27.000Z\"\n",
    "end_date = \"2021-12-31T01:15:27.000Z\"\n",
    "auto_stepsize = True\n",
    "history_end_date= \"2020-01-01T01:15:27.000Z\"\n",
    "step_size_str = \"D\"\n",
    "percentil = 0.5\n",
    "step_size_factor = 1.0\n",
    "min_amount_datapoints = 21\n",
    "interpolation_method = \"nearest\"\n",
    "fill_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = timeseries.drop(timeseries.index[[9,13,17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    timeseries=timeseries,\n",
    "    start_date_str=start_date,\n",
    "    end_date_str=end_date,\n",
    "    auto_stepsize=auto_stepsize,\n",
    "    history_end_date_str=history_end_date,\n",
    "    step_size_str=step_size_str,\n",
    "    step_size_factor=step_size_factor,\n",
    "    fill_value=fill_value,\n",
    "):\n",
    "    timeseries = timeseries.sort_index().dropna()\n",
    "\n",
    "    if start_date_str is None and \"start_date\" in timeseries.attrs:\n",
    "        start_date_str = timeseries.attrs[\"start_date\"]\n",
    "    if end_date_str is None and \"end_date\" in timeseries.attrs:\n",
    "        end_date_str = timeseries.attrs[\"end_date\"]\n",
    "\n",
    "    start_date = timestamp_str_to_pd_timestamp(start_date_str)\n",
    "    end_date = timestamp_str_to_pd_timestamp(end_date_str)\n",
    "    history_end_date = timestamp_str_to_pd_timestamp(history_end_date_str)\n",
    "\n",
    "    input_params = GapDetectionParameters(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        auto_stepsize=auto_stepsize,\n",
    "        history_end_date_str=history_end_date,\n",
    "        step_size_str=step_size_str,\n",
    "        percentil=percentil,\n",
    "        min_amount_datapoints=min_amount_datapoints,\n",
    "        interpolation_method=interpolation_method,\n",
    "        fill_value=fill_value,\n",
    "    )\n",
    "    series_with_bounds = check_add_boundary_dates(\n",
    "        timeseries, input_params.start_date, input_params.end_date\n",
    "    )\n",
    "    constricted_series = constrict_series_to_dates(\n",
    "        series_with_bounds, input_params.start_date, input_params.end_date\n",
    "    )\n",
    "\n",
    "    if auto_stepsize:\n",
    "        check_amount_datapoints(\n",
    "            series=constricted_series,\n",
    "            min_amount_datapoints=input_params.min_amount_datapoints,\n",
    "        )\n",
    "        if input_params.history_end_date is not None:\n",
    "            training_series = constrict_series_to_dates(\n",
    "                timeseries, input_params.start_date, input_params.history_end_date\n",
    "            )\n",
    "        else:\n",
    "            training_series = constricted_series\n",
    "        step_size = determine_timestep_gapsize_percentile(\n",
    "            training_series, percentil, interpolation_method\n",
    "        )\n",
    "    else:\n",
    "        step_size = freqstr2timedelta(step_size_str)\n",
    "\n",
    "\n",
    "    df_with_gaps = determine_gap_length(constricted_series, step_size)\n",
    "\n",
    "    return return_gap_boundary_timestamps(\n",
    "        df_with_gaps, constricted_series, step_size_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(timeseries, start_date_str, end_date_str, auto_stepsize, history_end_date_str, step_size_str, step_size_factor, fill_value)\u001b[0m\n\u001b[1;32m     55\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m freqstr2timedelta(step_size_str)\n\u001b[1;32m     58\u001b[0m df_with_gaps \u001b[38;5;241m=\u001b[39m determine_gap_length(constricted_series, step_size)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreturn_gap_boundary_timestamps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_with_gaps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstricted_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size_factor\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 29\u001b[0m, in \u001b[0;36mreturn_gap_boundary_timestamps\u001b[0;34m(frame_with_gapsizes, series, step_size_factor)\u001b[0m\n\u001b[1;32m     16\u001b[0m right_values \u001b[38;5;241m=\u001b[39m series[large_gap_indices]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to store the results\u001b[39;00m\n\u001b[1;32m     19\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     20\u001b[0m     {\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m: gap_starts,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m: large_gap_indices,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_inclusive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_inclusive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgap_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: large_gap_indices \u001b[38;5;241m-\u001b[39m gap_starts,\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_to_left\u001b[39m\u001b[38;5;124m\"\u001b[39m: left_values,\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_to_right\u001b[39m\u001b[38;5;124m\"\u001b[39m: right_values,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_left_right\u001b[39m\u001b[38;5;124m\"\u001b[39m: (left_values \u001b[38;5;241m+\u001b[39m right_values) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m     }\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_df\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hd-runtime-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
